{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjowcRQ2szV5l0fR3BUypK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/essat20/NLP_CW_210021102/blob/main/NLP_CW_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting Up The IDE and importing the libraries Before Pre-processing"
      ],
      "metadata": {
        "id": "JyWy0fRKbNrT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_QikHH8ZuSV"
      },
      "outputs": [],
      "source": [
        "# downloading datasets\n",
        "!pip install datasets # install the datasets from huggingface\n",
        "!pip install transformers # used for the BERT model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import DistilBertModel, DistilBertTokenizer, AdamW\n",
        "from datasets import load_dataset\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.optim import AdamW as aw\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import matplotlib.pyplot as plt # this can be used to display loss/epoch graphs\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "from sklearn.metrics import confusion_matrix # so i can display the confusion matrix"
      ],
      "metadata": {
        "id": "5pPC8MTTbTjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # prepares GPU\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset('emotion', trust_remote_code=True) # have to use the second parameter as there is required custom code for the dataset to be loaded properly"
      ],
      "metadata": {
        "id": "lXdBGW7TbZeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pre-processing the data"
      ],
      "metadata": {
        "id": "6cuuCkt1bx3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the DistilBert tokenizer and model\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "4EJn_V3KblnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below just defines the model architecture using a PyTorch neural network module. The SentimentClassifier class takes the DistilBERT model as input and defines the forward method. It extracts the last hidden state from the output of the DistilBERT model, and passes it through a linear layer to get the final logits."
      ],
      "metadata": {
        "id": "r04F6uImc--C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        self.model = model\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = outputs.last_hidden_state[:, 0, :]\n",
        "        logits = self.linear(last_hidden_state)\n",
        "        return logits.squeeze(-1)\n",
        "\n",
        "# Instantiate the model\n",
        "model = SentimentClassifier(model)"
      ],
      "metadata": {
        "id": "txx3DKtodWH9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}